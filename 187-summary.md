Modern chatbots' ability to generate text on a variety of topics using large language models (LLMs) represents impressive progress in artificial intelligence. These models can be trained on large amounts of text, allowing them to follow instructions and issue commands, making them general-purpose reasoning engines. They can control other components, including robots and online resources, and can understand and carry out tasks like "bring me the rice chips from the drawer." While there are concerns over their safety when connected to real-world contraptions, researchers are working to make them safer by training them with richer and more diverse datasets and augmenting their formal reasoning capabilities. Although LLMs have limited "context windows," researchers are working on post-transformer architectures that can support bigger context windows, which are crucial for improving their speed and performance. Some researchers believe that modern LLMs may be "doomed" and that building bigger models may not lead to artificial general intelligence (AGI), a long-sought-after goal. Nevertheless, these models represent significant progress in the field and can potentially drive progress in the next few years.